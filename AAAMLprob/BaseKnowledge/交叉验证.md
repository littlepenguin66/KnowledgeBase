交叉验证（Cross-validation）是一种统计学习方法，主要用于评估机器学习模型的性能和泛化能力。它通过将数据集分割成多个子集，然后使用其中的一部分进行模型训练，而使用剩余的部分进行模型验证，以此来减少模型对训练数据的依赖，提高模型的泛化能力。交叉验证的主要目的是避免过拟合（模型在训练数据上表现很好，但在未见过的数据上表现不佳）和欠拟合（模型在训练数据上表现不佳）。

交叉验证的常见类型包括：

1. **k-折交叉验证（k-fold cross-validation）**：将数据集分为k个等大小的子集。在k次迭代中，每次将其中一个子集用作验证集，其余k-1个子集用于训练模型。这样，每个子集都会被用作一次验证集。最终的模型性能评估是这k次验证结果的平均值。

2. **留一验证（Leave-one-out cross-validation, LOOCV）**：是k-折交叉验证的一种特殊情况，其中k等于数据集的大小。这意味着每次只使用一个样本作为验证集，其余样本用于训练模型。这种方法的计算量非常大，但可以提供非常精确的性能估计。

3. **自助法交叉验证（Bootstrap）**：通过从原始数据集中有放回地抽样来创建多个数据集（称为“自助集”），然后使用这些自助集进行交叉验证。这种方法可以提供更稳定的性能估计，尤其是在数据集较小的情况下。

交叉验证的选择取决于具体的应用场景、数据集的大小以及计算资源的可用性。在实践中，k-折交叉验证是最常用的方法，因为它在计算效率和性能估计的准确性之间取得了良好的平衡。